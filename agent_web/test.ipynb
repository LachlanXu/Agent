{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'field_validator' from 'pydantic' (c:\\Users\\xhx20\\.conda\\envs\\Pytorch\\Lib\\site-packages\\pydantic\\__init__.cp311-win_amd64.pyd)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_chroma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "File \u001b[1;32mc:\\Users\\xhx20\\.conda\\envs\\Pytorch\\Lib\\site-packages\\langchain_openai\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI, ChatOpenAI\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAIEmbeddings, OpenAIEmbeddings\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAI, OpenAI\n",
      "File \u001b[1;32mc:\\Users\\xhx20\\.conda\\envs\\Pytorch\\Lib\\site-packages\\langchain_openai\\chat_models\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mazure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAzureChatOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\xhx20\\.conda\\envs\\Pytorch\\Lib\\site-packages\\langchain_openai\\chat_models\\azure.py:24\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     Any,\n\u001b[0;32m     10\u001b[0m     Callable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     overload,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LanguageModelInput\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LangSmithParams\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseMessage\n",
      "File \u001b[1;32mc:\\Users\\xhx20\\.conda\\envs\\Pytorch\\Lib\\site-packages\\langchain_core\\language_models\\__init__.py:42\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"**Language Model** is a type of model that can generate text or complete\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mtext prompts.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     43\u001b[0m     BaseLanguageModel,\n\u001b[0;32m     44\u001b[0m     LangSmithParams,\n\u001b[0;32m     45\u001b[0m     LanguageModelInput,\n\u001b[0;32m     46\u001b[0m     LanguageModelLike,\n\u001b[0;32m     47\u001b[0m     LanguageModelOutput,\n\u001b[0;32m     48\u001b[0m     get_tokenizer,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseChatModel, SimpleChatModel\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FakeListLLM, FakeStreamingListLLM\n",
      "File \u001b[1;32mc:\\Users\\xhx20\\.conda\\envs\\Pytorch\\Lib\\site-packages\\langchain_core\\language_models\\base.py:21\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lru_cache\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     TYPE_CHECKING,\n\u001b[0;32m      7\u001b[0m     Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     Union,\n\u001b[0;32m     19\u001b[0m )\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, ConfigDict, Field, field_validator\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TypeAlias, TypedDict\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'field_validator' from 'pydantic' (c:\\Users\\xhx20\\.conda\\envs\\Pytorch\\Lib\\site-packages\\pydantic\\__init__.cp311-win_amd64.pyd)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.schema import Document\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from tqdm import tqdm\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "# 定义文件路径\n",
    "file_path = r\"C:\\Users\\xhx20\\Desktop\\Agent\\datasets\\TeleQnA.txt\"\n",
    "\n",
    "# 读取文件内容\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "# 提取问题及相关信息，转换为 Document 格式\n",
    "documents = []\n",
    "for key, value in data.items():\n",
    "    content = (\n",
    "        f\"Question: {value['question']}\\n\"\n",
    "        f\"Explanation: {value['explanation']}\\n\"\n",
    "        f\"Category: {value['category']}\"\n",
    "    )\n",
    "    documents.append(Document(page_content=content, metadata={\"id\": key}))\n",
    "\n",
    "\n",
    "print(\"start vector\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents,\n",
    "    embedding=OpenAIEmbeddings(\n",
    "        api_key=\"sk-nI4Wy7Ws2Tj2piRR6a65045dEcD7446c84BfF8BeD27a7d13\",\n",
    "        base_url=\"https://free.v36.cm/v1/\",\n",
    "    ),\n",
    "    persist_directory=r\"C:\\Users\\xhx20\\Desktop\\Agent\\agent_web\\vectorstore\"  # 可选，设置持久化路径\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'field_validator' from 'pydantic' (c:\\Users\\xhx20\\.conda\\envs\\Pytorch\\Lib\\site-packages\\pydantic\\__init__.cp311-win_amd64.pyd)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastAPI\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmiddleware\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CORSMiddleware\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PDFMinerParser\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Blob\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     AIMessage,\n\u001b[0;32m     13\u001b[0m     BaseMessage,\n\u001b[0;32m     14\u001b[0m     FunctionMessage,\n\u001b[0;32m     15\u001b[0m     HumanMessage,\n\u001b[0;32m     16\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\xhx20\\.conda\\envs\\Pytorch\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urlparse\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocuments\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseBlobParser\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblob_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Blob\n",
      "File \u001b[1;32mc:\\Users\\xhx20\\.conda\\envs\\Pytorch\\Lib\\site-packages\\langchain_core\\documents\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"**Document** module is a collection of classes that handle documents\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mand their transformations.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocuments\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocuments\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseDocumentCompressor\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocuments\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseDocumentTransformer\n",
      "File \u001b[1;32mc:\\Users\\xhx20\\.conda\\envs\\Pytorch\\Lib\\site-packages\\langchain_core\\documents\\base.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PurePath\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Generator, List, Literal, Optional, Union, cast\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfigDict, Field, field_validator, model_validator\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserializable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Serializable\n\u001b[0;32m     13\u001b[0m PathLike \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28mstr\u001b[39m, PurePath]\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'field_validator' from 'pydantic' (c:\\Users\\xhx20\\.conda\\envs\\Pytorch\\Lib\\site-packages\\pydantic\\__init__.cp311-win_amd64.pyd)"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"Endpoint shows off available playground widgets.\"\"\"\n",
    "import base64\n",
    "from json import dumps\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from langchain_community.document_loaders.parsers.pdf import PDFMinerParser\n",
    "from langchain_core.document_loaders import Blob\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    FunctionMessage,\n",
    "    HumanMessage,\n",
    ")\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langserve import CustomUserType\n",
    "from langserve.server import add_routes\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"LangChain Server\",\n",
    "    version=\"1.0\",\n",
    "    description=\"Spin up a simple api server using Langchain's Runnable interfaces\",\n",
    ")\n",
    "\n",
    "\n",
    "# Set all CORS enabled origins\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    "    expose_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Example 1: Chat Widget\n",
    "# This shows how to create a chat widget.\n",
    "\n",
    "\n",
    "class ChatHistory(CustomUserType):\n",
    "    chat_history: List[Tuple[str, str]] = Field(\n",
    "        ...,\n",
    "        examples=[[(\"a\", \"aa\")]],\n",
    "        extra={\"widget\": {\"type\": \"chat\", \"input\": \"question\", \"output\": \"answer\"}},\n",
    "    )\n",
    "    question: str\n",
    "\n",
    "\n",
    "def _format_to_messages(input: ChatHistory) -> List[BaseMessage]:\n",
    "    \"\"\"Format the input to a list of messages.\"\"\"\n",
    "    history = input.chat_history\n",
    "    user_input = input.question\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    for human, ai in history:\n",
    "        messages.append(HumanMessage(content=human))\n",
    "        messages.append(AIMessage(content=ai))\n",
    "    messages.append(HumanMessage(content=user_input))\n",
    "    return messages\n",
    "\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    api_key=\"sk-nI4Wy7Ws2Tj2piRR6a65045dEcD7446c84BfF8BeD27a7d13\",\n",
    "    base_url=\"https://free.v36.cm/v1/\",\n",
    ")\n",
    "chat_model = RunnableParallel({\"answer\": (RunnableLambda(_format_to_messages) | model)})\n",
    "add_routes(\n",
    "    app,\n",
    "    chat_model.with_types(input_type=ChatHistory),\n",
    "    config_keys=[\"configurable\"],\n",
    "    path=\"/chat\",\n",
    ")\n",
    "\n",
    "\n",
    "# Example 2: Chat Widget with History\n",
    "# This one isn't hooked up toa model. It just shows that FunctionMessages can be used\n",
    "# surfaced as well in the playground.\n",
    "\n",
    "\n",
    "class ChatHistoryMessage(BaseModel):\n",
    "    chat_history: List[BaseMessage] = Field(\n",
    "        ...,\n",
    "        extra={\"widget\": {\"type\": \"chat\", \"input\": \"location\"}},\n",
    "    )\n",
    "    location: str\n",
    "\n",
    "\n",
    "def chat_message_bot(input: Dict[str, Any]) -> List[BaseMessage]:\n",
    "    \"\"\"Bot that repeats the question twice.\"\"\"\n",
    "    return [\n",
    "        AIMessage(\n",
    "            content=\"\",\n",
    "            additional_kwargs={\n",
    "                \"function_call\": {\n",
    "                    \"name\": \"get_weather\",\n",
    "                    \"arguments\": dumps({\"location\": input[\"location\"]}),\n",
    "                }\n",
    "            },\n",
    "        ),\n",
    "        FunctionMessage(name=\"get_weather\", content='{\"value\": 32}'),\n",
    "        AIMessage(content=f\"Weather in {input['location']}: 32\"),\n",
    "    ]\n",
    "\n",
    "\n",
    "add_routes(\n",
    "    app,\n",
    "    RunnableLambda(chat_message_bot).with_types(input_type=ChatHistoryMessage),\n",
    "    config_keys=[\"configurable\"],\n",
    "    path=\"/chat_message\",\n",
    ")\n",
    "\n",
    "# Example 3: File Processing Widget\n",
    "\n",
    "\n",
    "class FileProcessingRequest(BaseModel):\n",
    "    file: bytes = Field(..., extra={\"widget\": {\"type\": \"base64file\"}})\n",
    "    num_chars: int = 100\n",
    "\n",
    "\n",
    "def process_file(input: Dict[str, Any]) -> str:\n",
    "    \"\"\"Extract the text from the first page of the PDF.\"\"\"\n",
    "    content = base64.decodebytes(input[\"file\"])\n",
    "    blob = Blob(data=content)\n",
    "    documents = list(PDFMinerParser().lazy_parse(blob))\n",
    "    content = documents[0].page_content\n",
    "    return content[: input[\"num_chars\"]]\n",
    "\n",
    "\n",
    "add_routes(\n",
    "    app,\n",
    "    RunnableLambda(process_file).with_types(input_type=FileProcessingRequest),\n",
    "    config_keys=[\"configurable\"],\n",
    "    path=\"/pdf\",\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "\n",
    "    uvicorn.run(app, host=\"localhost\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in c:\\users\\xhx20\\.conda\\envs\\pytorch\\lib\\site-packages (1.10.0)\n",
      "Collecting pydantic\n",
      "  Obtaining dependency information for pydantic from https://files.pythonhosted.org/packages/d5/74/da832196702d0c56eb86b75bfa346db9238617e29b0b7ee3b8b4eccfe654/pydantic-2.10.2-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.10.2-py3-none-any.whl.metadata (170 kB)\n",
      "     ------------------------------------ 170.8/170.8 kB 513.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\xhx20\\.conda\\envs\\pytorch\\lib\\site-packages (from pydantic) (0.6.0)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic)\n",
      "  Obtaining dependency information for pydantic-core==2.27.1 from https://files.pythonhosted.org/packages/6a/fe/4e0e63c418c1c76e33974a05266e5633e879d4061f9533b1706a86f77d5b/pydantic_core-2.27.1-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading pydantic_core-2.27.1-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from pydantic)\n",
      "  Obtaining dependency information for typing-extensions>=4.12.2 from https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading pydantic-2.10.2-py3-none-any.whl (456 kB)\n",
      "   ---------------------------------------- 456.4/456.4 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.27.1-cp311-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 2.0/2.0 MB 6.3 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, pydantic-core, pydantic\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.23.4\n",
      "    Uninstalling pydantic_core-2.23.4:\n",
      "      Successfully uninstalled pydantic_core-2.23.4\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.0\n",
      "    Uninstalling pydantic-1.10.0:\n",
      "      Successfully uninstalled pydantic-1.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] 拒绝访问。: 'C:\\\\Users\\\\xhx20\\\\.conda\\\\envs\\\\Pytorch\\\\Lib\\\\site-packages\\\\~ydantic\\\\annotated_types.cp311-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
